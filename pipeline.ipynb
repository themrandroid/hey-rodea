{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "802ac9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from faster_whisper import WhisperModel\n",
    "import collections\n",
    "import contextlib\n",
    "import wave\n",
    "import webrtcvad\n",
    "import re\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2421e4",
   "metadata": {},
   "source": [
    "### ASR with Word-Level Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775caa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper (tiny or small)\n",
    "model = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8\")  \n",
    "\n",
    "def transcribe_with_timestamps(audio_path, output_json):\n",
    "    segments, info = model.transcribe(audio_path, word_timestamps=True)\n",
    "    \n",
    "    words = []\n",
    "    for segment in segments:\n",
    "        for w in segment.words:  # each word has start, end, and text\n",
    "            words.append({\n",
    "                \"word\": w.word.strip(),\n",
    "                \"start\": round(w.start, 2),\n",
    "                \"end\": round(w.end, 2)\n",
    "            })\n",
    "\n",
    "    # Save JSON\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(words, f, indent=2)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb9ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: run ASR for first 3 files in metadata\n",
    "df = pd.read_csv(\"metadata.csv\")\n",
    "out_dir = \"asr_json\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    audio_path = row[\"file\"]\n",
    "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    out_path = os.path.join(out_dir, f\"{base_name}.json\")\n",
    "\n",
    "    if not os.path.exists(out_path):  # skip if already done\n",
    "        print(f\"Transcribing {audio_path} ...\")\n",
    "        words = transcribe_with_timestamps(audio_path, out_path)\n",
    "        print(f\"  Saved {len(words)} words → {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ebf80",
   "metadata": {},
   "source": [
    "### Silence Detection from Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: read audio (16kHz WAV mono)\n",
    "def read_wave(path):\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1, \"Audio must be mono\"\n",
    "        # sample_width = wf.getsampwidth()\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate == 16000, \"Audio must be 16kHz\"\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "# Frame container\n",
    "class Frame(object):\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "# Frame generator\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n <= len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "# Speech segment collector\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "\n",
    "    triggered = False\n",
    "    segments = []\n",
    "    start_time = 0\n",
    "\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                start_time = ring_buffer[0][0].timestamp\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                end_time = frame.timestamp + frame.duration\n",
    "                segments.append((start_time, end_time))\n",
    "                triggered = False\n",
    "                ring_buffer.clear()\n",
    "\n",
    "    if triggered:\n",
    "        end_time = frame.timestamp + frame.duration\n",
    "        segments.append((start_time, end_time))\n",
    "\n",
    "    return segments\n",
    "\n",
    "# High-level pause detector\n",
    "def detect_pauses(audio_path, aggressiveness=2):\n",
    "    pcm_data, sample_rate = read_wave(audio_path)\n",
    "    vad = webrtcvad.Vad(aggressiveness)  # 0–3 (3 = most aggressive)\n",
    "\n",
    "    frames = list(frame_generator(30, pcm_data, sample_rate))\n",
    "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "\n",
    "    # Compute pauses as gaps between speech segments\n",
    "    pauses = []\n",
    "    prev_end = 0.0\n",
    "    for start, end in segments:\n",
    "        if prev_end > 0:\n",
    "            pause_dur = start - prev_end\n",
    "            if pause_dur > 0.2:  # ignore very short gaps\n",
    "                pauses.append((round(prev_end, 2), round(start, 2)))\n",
    "        prev_end = end\n",
    "\n",
    "    return pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22401a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected pauses: [(3.12, 4.05), (5.37, 5.58), (6.84, 7.5), (11.16, 11.85)]\n"
     ]
    }
   ],
   "source": [
    "pauses = detect_pauses(\"librispeech_subset_wav\\sample_156.wav\")\n",
    "print(\"Detected pauses:\", pauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d11ea5",
   "metadata": {},
   "source": [
    "### Pace (Words Per Minute, WPM) and Filler Count & Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f2b11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILLER_WORDS = [\n",
    "    \"um\", \"uh\", \"erm\", \"like\", \"you know\",\n",
    "    \"sort of\", \"kind of\", \"so\", \"hmm\",\n",
    "    \"i mean\", \"actually\", \"basically\"\n",
    "]\n",
    "\n",
    "def normalize_text(word):\n",
    "    \"\"\"Lowercasing and stripping punctuation for matching.\"\"\"\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", word.lower())\n",
    "\n",
    "def compute_wpm_and_fillers(asr_json_path, pauses, long_pause_threshold=2.0):\n",
    "    with open(asr_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        words = json.load(f)\n",
    "\n",
    "    total_words = len(words)\n",
    "    if total_words == 0:\n",
    "        return {\n",
    "            \"WPM\": 0, \"total_words\": 0, \"effective_time_sec\": 0,\n",
    "            \"filler_count\": 0, \"filler_density\": 0.0, \"top_fillers\": {}\n",
    "        }\n",
    "\n",
    "    # --- Effective speaking time ---\n",
    "    start_time = words[0][\"start\"]\n",
    "    end_time = words[-1][\"end\"]\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    long_pauses = [end - start for start, end in pauses if (end - start) > long_pause_threshold]\n",
    "    effective_time = total_time - sum(long_pauses)\n",
    "    if effective_time <= 0:\n",
    "        effective_time = total_time  # fallback\n",
    "\n",
    "    wpm = total_words / (effective_time / 60)\n",
    "\n",
    "    # --- Filler detection ---\n",
    "    filler_count = 0\n",
    "    filler_hist = {}\n",
    "\n",
    "    for w in words:\n",
    "        token = normalize_text(w[\"word\"])\n",
    "        if token in FILLER_WORDS:\n",
    "            filler_count += 1\n",
    "            filler_hist[token] = filler_hist.get(token, 0) + 1\n",
    "\n",
    "    filler_density = filler_count / total_words if total_words > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"WPM\": round(wpm, 2),\n",
    "        \"total_words\": total_words,\n",
    "        \"effective_time_sec\": round(effective_time, 2),\n",
    "        \"total_time_sec\": round(total_time, 2),\n",
    "        \"long_pauses_count\": len(long_pauses),\n",
    "        \"long_pauses_total_sec\": round(sum(long_pauses), 2),\n",
    "        \"filler_count\": filler_count,\n",
    "        \"filler_density\": round(filler_density, 4),\n",
    "        \"top_fillers\": dict(sorted(filler_hist.items(), key=lambda x: -x[1]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a86501dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WPM': 141.43, 'total_words': 33, 'effective_time_sec': 14.0, 'total_time_sec': 14.0, 'long_pauses_count': 0, 'long_pauses_total_sec': 0, 'filler_count': 1, 'filler_density': 0.0303, 'top_fillers': {'like': 1}}\n"
     ]
    }
   ],
   "source": [
    "asr_json = \"asr_json/sample_147.json\"\n",
    "pauses = detect_pauses(\"librispeech_subset_wav\\sample_147.wav\")\n",
    "\n",
    "stats = compute_wpm_and_fillers(asr_json, pauses)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef57fed",
   "metadata": {},
   "source": [
    "### Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ce8b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(stats, pauses, total_time_sec):\n",
    "\n",
    "    # 1. Clarity\n",
    "    filler_density = stats[\"filler_density\"]\n",
    "    long_pause_rate_per_min = stats[\"long_pauses_count\"] / (total_time_sec / 60) if total_time_sec > 0 else 0\n",
    "\n",
    "    clarity = 100\n",
    "    clarity -= min(40, 400 * filler_density)\n",
    "    clarity -= min(20, 10 * long_pause_rate_per_min)\n",
    "    clarity = max(0, min(100, round(clarity, 2)))\n",
    "\n",
    "    # 2. Confidence\n",
    "    WPM = stats[\"WPM\"]\n",
    "    target_mid, target_span = 165, 15\n",
    "    conf_score = 100 - min(50, abs(WPM - target_mid) / target_span * 100)\n",
    "\n",
    "    # Placeholder for variability penalty\n",
    "    std_local_WPM = 0  # could compute later from 30s windows\n",
    "    conf_score -= min(20, 5 * std_local_WPM)\n",
    "    confidence = max(0, min(100, round(conf_score, 2)))\n",
    "\n",
    "    # 3. Engagement\n",
    "    pauses_per_min = len(pauses) / (total_time_sec / 60) if total_time_sec > 0 else 0\n",
    "    pause_lengths = [end - start for start, end in pauses]\n",
    "    median_pause = np.median(pause_lengths) if pause_lengths else 0\n",
    "\n",
    "    engagement = 60\n",
    "\n",
    "    # Pause cadence bonus\n",
    "    if 6 <= pauses_per_min <= 15 and 0.3 <= median_pause <= 1.2:\n",
    "        engagement += 15\n",
    "    elif pauses_per_min > 0:\n",
    "        engagement += 10  # partial credit\n",
    "\n",
    "    # Energy/pitch bonus (stub for MVP)\n",
    "    engagement += 10  # later refine with RMS variance\n",
    "\n",
    "    engagement = max(0, min(100, round(engagement, 2)))\n",
    "\n",
    "    return {\n",
    "        \"Clarity\": clarity,\n",
    "        \"Confidence\": confidence,\n",
    "        \"Engagement\": engagement\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6aa6f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Clarity': 100, 'Confidence': 91.4, 'Engagement': 80}\n"
     ]
    }
   ],
   "source": [
    "asr_json = \"asr_json/sample_14.json\"\n",
    "pauses = detect_pauses(\"librispeech_subset_wav\\sample_14.wav\")\n",
    "\n",
    "stats = compute_wpm_and_fillers(asr_json, pauses)\n",
    "total_time_sec = stats[\"total_time_sec\"]\n",
    "scores = compute_scores(stats, pauses, total_time_sec)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a7593",
   "metadata": {},
   "source": [
    "### Feedback Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3732d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback(stats, scores, pauses, total_time_sec, long_thr=2.0):\n",
    "    feedback = []\n",
    "\n",
    "    # Fillers\n",
    "    if stats[\"filler_count\"] > 0:\n",
    "        top_filler = max(stats[\"top_fillers\"], key=stats[\"top_fillers\"].get, default=None)\n",
    "        feedback.append(\n",
    "            f\"You used {stats['filler_count']} filler words\"\n",
    "            + (f\", mostly '{top_filler}'\" if top_filler else \"\")\n",
    "            + \". Try a short silent pause when you need to think.\"\n",
    "        )\n",
    "\n",
    "    # Pace (WPM)\n",
    "    if stats[\"WPM\"] > 190:\n",
    "        feedback.append(\n",
    "            f\"Your pace averaged {stats['WPM']} WPM — a bit fast. \"\n",
    "            \"Aim for 150–180 WPM for clarity.\"\n",
    "        )\n",
    "    elif stats[\"WPM\"] < 120:\n",
    "        feedback.append(\n",
    "            f\"Your pace averaged {stats['WPM']} WPM — a bit slow. \"\n",
    "            \"Aim for 150–180 WPM for better engagement.\"\n",
    "        )\n",
    "\n",
    "    # Pauses\n",
    "    pauses_per_min = len(pauses) / (total_time_sec / 60) if total_time_sec > 0 else 0\n",
    "    pause_lengths = [end - start for start, end in pauses]\n",
    "    median_pause = np.median(pause_lengths) if pause_lengths else 0\n",
    "\n",
    "    if pauses_per_min < 3:\n",
    "        feedback.append(\n",
    "            f\"Pauses were scarce ({pauses_per_min:.1f}/min). \"\n",
    "            \"Add brief pauses to separate ideas.\"\n",
    "        )\n",
    "    elif any((end - start) > long_thr for start, end in pauses):\n",
    "        feedback.append(\n",
    "            f\"Several long pauses (>{long_thr}s). \"\n",
    "            \"Consider shorter, intentional breaths between points.\"\n",
    "        )\n",
    "    else:\n",
    "        feedback.append(\n",
    "            f\"Great balance of pauses (median {median_pause:.1f}s). \"\n",
    "            \"Keeps the audience with you!\"\n",
    "        )\n",
    "\n",
    "    # Always include a positive reinforcement\n",
    "    if scores[\"Clarity\"] > 75:\n",
    "        feedback.append(\"Nice clarity overall — your message came through well!\")\n",
    "    elif scores[\"Confidence\"] > 75:\n",
    "        feedback.append(\"You sounded confident — good pacing and delivery.\")\n",
    "    else:\n",
    "        feedback.append(\"Solid effort — keep practicing to improve further!\")\n",
    "\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "01a7892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Your pace averaged 211.06 WPM — a bit fast. Aim for 150–180 WPM for clarity.\n",
      "- Great balance of pauses (median 0.3s). Keeps the audience with you!\n",
      "- Nice clarity overall — your message came through well!\n"
     ]
    }
   ],
   "source": [
    "asr_json = \"asr_json/sample_179.json\"\n",
    "pauses = detect_pauses(\"librispeech_subset_wav\\sample_179.wav\")\n",
    "\n",
    "stats = compute_wpm_and_fillers(asr_json, pauses)\n",
    "total_time_sec = stats[\"total_time_sec\"]\n",
    "scores = compute_scores(stats, pauses, total_time_sec)\n",
    "fb = generate_feedback(stats, scores, pauses, total_time_sec)\n",
    "for line in fb:\n",
    "    print(\"-\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c4204c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'Clarity': 87.88, 'Confidence': 50, 'Engagement': 80}\n",
      "Feedback:\n",
      "- You used 1 filler words, mostly 'like'. Try a short silent pause when you need to think.\n",
      "- Great balance of pauses (median 0.5s). Keeps the audience with you!\n",
      "- Nice clarity overall — your message came through well!\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "audio_path = \"librispeech_subset_wav/sample_147.wav\"\n",
    "asr_json = \"asr_json/sample_147.json\"\n",
    "\n",
    "# 1. Pause detection\n",
    "pauses = detect_pauses(audio_path)\n",
    "\n",
    "# 2. WPM + fillers\n",
    "stats = compute_wpm_and_fillers(asr_json, pauses)\n",
    "\n",
    "# 3. Scores\n",
    "scores = compute_scores(stats, pauses, stats[\"total_time_sec\"])\n",
    "\n",
    "# 4. Feedback\n",
    "feedback = generate_feedback(stats, scores, pauses, stats[\"total_time_sec\"])\n",
    "\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Feedback:\")\n",
    "for line in feedback:\n",
    "    print(\"-\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5eaaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_speech(audio_path, asr_out_dir=\"asr_json\"):\n",
    "    # Ensure ASR output dir exists\n",
    "    os.makedirs(asr_out_dir, exist_ok=True)\n",
    "\n",
    "    # ------------------\n",
    "    # 1. ASR\n",
    "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    asr_json_path = os.path.join(asr_out_dir, f\"{base_name}.json\")\n",
    "\n",
    "    if not os.path.exists(asr_json_path):\n",
    "        transcribe_with_timestamps(audio_path, asr_json_path)\n",
    "\n",
    "    # ------------------\n",
    "    # 2. Pause detection\n",
    "    pauses = detect_pauses(audio_path)\n",
    "\n",
    "    # ------------------\n",
    "    # 3. Stats (WPM + fillers)\n",
    "    stats = compute_wpm_and_fillers(asr_json_path, pauses)\n",
    "\n",
    "    # ------------------\n",
    "    # 4. Scores\n",
    "    scores = compute_scores(stats, pauses, stats[\"total_time_sec\"])\n",
    "\n",
    "    # ------------------\n",
    "    # 5. Feedback\n",
    "    feedback = generate_feedback(stats, scores, pauses, stats[\"total_time_sec\"])\n",
    "\n",
    "    return {\n",
    "        \"asr_json\": asr_json_path,\n",
    "        \"pauses\": pauses,\n",
    "        \"stats\": stats,\n",
    "        \"scores\": scores,\n",
    "        \"feedback\": feedback\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "760c8140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asr_json': 'asr_json\\\\sample_147.json', 'pauses': [(2.01, 2.22), (4.8, 6.3), (8.64, 9.06), (11.43, 11.94)], 'stats': {'WPM': 141.43, 'total_words': 33, 'effective_time_sec': 14.0, 'total_time_sec': 14.0, 'long_pauses_count': 0, 'long_pauses_total_sec': 0, 'filler_count': 1, 'filler_density': 0.0303, 'top_fillers': {'like': 1}}, 'scores': {'Clarity': 87.88, 'Confidence': 50, 'Engagement': 80}, 'feedback': [\"You used 1 filler words, mostly 'like'. Try a short silent pause when you need to think.\", 'Great balance of pauses (median 0.5s). Keeps the audience with you!', 'Nice clarity overall — your message came through well!']}\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"librispeech_subset_wav/sample_147.wav\"\n",
    "result = analyze_speech(audio_path)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
